#!/usr/bin/env python3
"""
Script de prueba para el sistema RAG con embeddings locales
"""

import os
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

print("âœ… Variables de entorno cargadas")

# Probar el sistema RAG completo con embeddings locales
try:
    from app.services.embedding_service import EmbeddingService
    from app.services.chunking_service import ChunkingService, ChunkingStrategy
    from app.services.retrieval_service import RetrievalService
    from app.services.generation_service import GenerationService
    
    print("ğŸ”— Inicializando servicios con embeddings locales...")
    
    # Usar embeddings locales
    embedding_service = EmbeddingService(use_local=True)
    
    # Inicializar otros servicios
    chunking_service = ChunkingService(
        strategy=ChunkingStrategy.RECURSIVE_CHARACTER,
        chunk_size=1000,
        chunk_overlap=200
    )
    
    retrieval_service = RetrievalService()
    generation_service = GenerationService()
    
    print("âœ… Todos los servicios inicializados correctamente")
    
    # Probar chunking
    print("ğŸ§ª Probando chunking...")
    chunks = chunking_service.process_collection("test_collection")
    print(f"âœ… Chunking completado: {len(chunks)} chunks generados")
    
    if chunks:
        # Probar creaciÃ³n de vector store
        print("ğŸ§ª Probando creaciÃ³n de vector store...")
        success, stats = retrieval_service.create_vector_store(
            documents=chunks,
            collection_name="test_collection_local",
            force_rebuild=True,
            embedding_service=embedding_service,
            batch_size=10  # Batch pequeÃ±o para prueba
        )
        
        if success:
            print("âœ… Vector store creado exitosamente")
            print(f"ğŸ“Š EstadÃ­sticas: {stats}")
            
            # Probar bÃºsqueda
            print("ğŸ§ª Probando bÃºsqueda semÃ¡ntica...")
            retrieved_docs = retrieval_service.similarity_search(
                query="Â¿De quÃ© trata el documento?",
                collection_name="test_collection_local",
                k=3,
                embedding_service=embedding_service
            )
            
            print(f"âœ… BÃºsqueda completada: {len(retrieved_docs)} documentos encontrados")
            
            if retrieved_docs:
                # Probar generaciÃ³n de respuesta
                print("ğŸ§ª Probando generaciÃ³n de respuesta...")
                result = generation_service.generate_response(
                    question="Â¿De quÃ© trata el documento?",
                    retrieved_docs=retrieved_docs
                )
                
                print("âœ… Respuesta generada:")
                print(f"ğŸ“ Respuesta: {result['answer']}")
                print(f"ğŸ“„ Fuentes: {result['sources']}")
                
        else:
            print(f"âŒ Error creando vector store: {stats}")
    
    print("ğŸ‰ Sistema RAG con embeddings locales funciona correctamente!")
    
except Exception as e:
    print(f"âŒ Error en el sistema RAG: {str(e)}")
    import traceback
    traceback.print_exc()


